{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sja2yrG9zRSS",
        "outputId": "e2c32658-1eb3-48c5-b684-2c0ab2ebdb62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
      ],
      "metadata": {
        "id": "xmFSA7xVzXZi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"TextClassifierwithPySpark\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "PKBdkOQMzdhl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the datasets\n",
        "df = spark.read.parquet('Apparel_v1_00/amazon_us_reviews-train-00000-of-00005.parquet')"
      ],
      "metadata": {
        "id": "G4lGaxXjzfhE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'star_rating' column to string type\n",
        "df = df.withColumn('star_rating', df['star_rating'].cast('string'))"
      ],
      "metadata": {
        "id": "DxmimG2KB5Wy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'review_body' column to string type\n",
        "df = df.withColumn('review_body', df['review_body'].cast('string'))\n"
      ],
      "metadata": {
        "id": "iHywNFSezohe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply label encoding based on star_rating\n",
        "df = df.withColumn('label', (df['star_rating'] > '3').cast('integer'))\n"
      ],
      "metadata": {
        "id": "w5XCqKGFzsfJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the preprocess_text function\n",
        "def preprocess_text(text):\n",
        "    # Remove punctuation\n",
        "    import re\n",
        "    import string\n",
        "    text = re.sub('[' + string.punctuation + ']', '', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove extra whitespaces\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "rAMIC0Quz7Rj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a UDF for the preprocess_text function\n",
        "from pyspark.sql.functions import udf\n",
        "preprocess_udf = udf(preprocess_text)"
      ],
      "metadata": {
        "id": "AyOMBM1TDFNZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the preprocess_text function to the 'review_body' column\n",
        "df = df.withColumn('review_body', preprocess_udf('review_body'))\n"
      ],
      "metadata": {
        "id": "zANWuRaZDFx1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns for training\n",
        "df = df.select('review_body', 'label')"
      ],
      "metadata": {
        "id": "IFyoEcBcDHyw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "trainDF, testDF = df.randomSplit([0.7, 0.3], seed=42)"
      ],
      "metadata": {
        "id": "Zy7eEfv5DJgW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the stages for the pipeline\n",
        "tokenizer = Tokenizer(inputCol='review_body', outputCol='mytokens')\n",
        "stopwords_remover = StopWordsRemover(inputCol='mytokens', outputCol='filtered_tokens')\n",
        "vectorizer = CountVectorizer(inputCol='filtered_tokens', outputCol='rawFeatures')\n",
        "idf = IDF(inputCol='rawFeatures', outputCol='vectorizedFeatures')\n",
        "svm = LinearSVC(featuresCol='vectorizedFeatures', labelCol='label')"
      ],
      "metadata": {
        "id": "m0k72bh3DK6M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the pipeline\n",
        "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, vectorizer, idf, svm])\n"
      ],
      "metadata": {
        "id": "ahL4wDl7DMX6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the pipeline on the training data\n",
        "svm_model = pipeline.fit(trainDF)"
      ],
      "metadata": {
        "id": "Tt-_XutDMA3V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the testing data\n",
        "predictions = svm_model.transform(testDF)\n"
      ],
      "metadata": {
        "id": "mW-Mq4XcNtnN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
        "accuracy = evaluator.evaluate(predictions)"
      ],
      "metadata": {
        "id": "yDHuOMpkMBXU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the accuracy\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITh1lU5XMC2B",
        "outputId": "cde8a77c-75ca-4e0c-b7b2-3885c7da92fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 87.43%\n"
          ]
        }
      ]
    }
  ]
}